#########################################################################
# Title:         Cloudbox: Backup Role                                  #
# Author(s):     l3uddz, desimaniac, RXWatcher1                         #
# URL:           https://github.com/cloudbox/cloudbox                   #
# --                                                                    #
#         Part of the Cloudbox project: https://cloudbox.works          #
#########################################################################
#                   GNU General Public License v3.0                     #
#########################################################################
---
- block:
  - name: Sanity Check
    import_tasks: "sanity_check.yml"

  - name: Variables
    import_tasks: "variables.yml"
    tags:
      - set-backup
      - restore-service
      - cloudbox-restore-service

  - name: Cron
    import_tasks: "cron.yml"
    when: ('set-backup' in ansible_run_tags) and not ('backup' in ansible_run_tags)
    tags: set-backup

  - name: Get Current Time
    shell: "date \"+%s\""
    register: start_time_lookup

  - name: "Set 'start_time' variable"
    set_fact:
      start_time: "{{ start_time_lookup.stdout }}"

  - name: Snapshot
    import_tasks: "snapshot.yml"

  - name: "Pushover Message: Started Cloudbox backup task"
    include_role:
      name: pushover
    vars:
      message: "Started Cloudbox {{ use_snapshot | ternary('(snapshot-enabled) ','') }}backup task."

  - name: "Create 'backup.lock'."
    file:
      path: "{{ playbook_dir }}/backup.lock"
      state: touch
      owner: "{{ user }}"
      group: "{{ user }}"
      mode: 0775

  - name: Check if previous backup exists locally
    find:
      paths: "{{ local.destination }}"
      file_type: file
      patterns: '*.tar'
      recurse: yes
    register: dir_files

  # Remove backup.old folder if it exists.
  - name: "Remove '{{ local.destination }}.old'"
    file:
      path: "{{ local.destination }}.old"
      state: absent

  # Use mv because Ansible copy & delete takes a lot longer.
  - name: "Moving '{{ local.destination }}' to '{{ local.destination }}.old'"
    shell: "mv '{{ local.destination }}' '{{ local.destination }}.old'"
    become: yes
    become_user: "{{ user }}"
    when: dir_files.matched|int != 0

  - name: "Create backup folders."
    file: "path={{ item }} state=directory mode=0775 owner={{ user }} group={{ user }} recurse=yes"
    with_items:
      - "/home/{{ user }}/logs"
      - "/home/{{ user }}/logs/backup"
      - "{{ local.destination }}"
      - "{{ local.destination }}/opt"
      - "/opt/systemd-backup"
      - "/opt/crontab-backup"

  - name: "Copy files to '{{ local.destination }}'"
    copy:
      src: "{{ item }}"
      dest: "{{ local.destination }}"
      owner: "{{ user }}"
      group: "{{ user }}"
      mode: 0775
      force: yes
    with_items:
     - "{{ playbook_dir }}/ansible.cfg"
     - "{{ playbook_dir }}/accounts.yml"
     - "{{ playbook_dir }}/settings.yml"
     - "{{ playbook_dir }}/adv_settings.yml"
     - "{{ playbook_dir }}/backup_config.yml"
     - "/home/{{ user }}/.config/rclone/rclone.conf"
    ignore_errors: yes

  - name: "Look for 'backup_excludes_list.txt' file in cloudbox folder"
    stat:
      path: "{{ playbook_dir }}/backup_excludes_list.txt"
    register: backup_excludes_list

  - name: "Copy files to '{{ local.destination }}'."
    copy:
      src: "{{ playbook_dir }}/backup_excludes_list.txt"
      dest: "{{ local.destination }}"
      owner: "{{ user }}"
      group: "{{ user }}"
      mode: 0775
      force: yes
    when: (backup_excludes_list.stat.exists)

  - name: Cloudbox Restore Service
    import_tasks: "restore_service.yml"
    when: restore_service_enabled
    tags:
      - restore-service
      - cloudbox-restore-service

  - name: "Synchronize '/etc/systemd/system' to '/opt/systemd-backup' for inclusion in backup"
    shell: |
      /usr/bin/rsync \
        --delay-updates \
        -F \
        --compress \
        --archive \
        --no-recursive \
        --no-links \
        --no-perms \
        --include='*.service' \
        --include='*.mount' \
        /etc/systemd/system/* /opt/systemd-backup/
    args:
      executable: /bin/bash
      warn: no
    ignore_errors: yes

  - name: "Copying crontabs to '/opt/crontab-backup' for inclusion in backup"
    shell: "cp -f /var/spool/cron/crontabs/* /opt/crontab-backup"
    ignore_errors: yes

  - name: "Reset permissions of folders"
    file: "path={{ item }} state=directory mode=0775 owner={{ user }} group={{ user }} recurse=yes"
    with_items:
      - "/opt/systemd-backup"
      - "/opt/crontab-backup"

  - name: Populate Service Facts
    service_facts:

  # Stop Containers

  - name: "Gather list of running Docker containers"
    shell: "docker ps --format '{{ '{{' }} .Names{{ '}}' }}' --filter label=com.github.cloudbox.cloudbox_managed=true | xargs echo -n"
    register: cloudbox_managed_containers
    ignore_errors: yes

  - name: "Stop all running Docker containers"
    shell: "docker stop {{ cloudbox_managed_containers.stdout }}"
    ignore_errors: yes
    when: (cloudbox_managed_containers.stdout | trim | length > 0)

  - name: "Pushover Message: Stopped Docker containers"
    include_role:
      name: pushover
    vars:
      message: "Stopped Docker containers."
    when: (cloudbox_managed_containers.stdout | trim | length > 0)

  # Stop Plexdrive

  - name: Check if 'plexdrive.service' exists
    stat:
      path: "/etc/systemd/system/plexdrive.service"
    register: plexdrive_service

  - name: Get plexdrive service state
    set_fact:
      plexdrive_service_running: "{{ (services['plexdrive.service'] is defined) and (services['plexdrive.service']['state'] == 'running') }}"
    when: (plexdrive_service.stat.exists)

  - name: Stop plexdrive service
    systemd:
      name: plexdrive
      state: stopped
    when: (plexdrive_service.stat.exists) and (plexdrive_service_running)

  # Stop Cloudplow

  - name: Check if 'cloudplow.service' exists
    stat:
      path: "/etc/systemd/system/cloudplow.service"
    register: cloudplow_service

  - name: Get cloudplow service state
    set_fact:
      cloudplow_service_running: "{{ (services['cloudplow.service'] is defined) and (services['cloudplow.service']['state'] == 'running') }}"
    when: (cloudplow_service.stat.exists)

  - name: Stop cloudplow service
    systemd:
      name: cloudplow
      state: stopped
    when: (cloudplow_service.stat.exists) and (cloudplow_service_running)

  # Create snapshot

  - name: Create Snapshot
    block:

    - name: "Snapshot | Wait for 5 seconds before creating snapshot"
      wait_for:
        timeout: 5

    - name: Snapshot | Display snapshot destination
      debug:
        msg: "Creating snapshot of '/opt/' in '{{ backup_root_path }}/' ..."

    - name: Snapshot | Create btrfs snapshot
      shell: 'btrfs subvolume snapshot / /btrfs/snapshots/root'
      when: (snapshot_type == 'btrfs')

    - name: Snapshot | Display location of '/opt/' folder in snapshot
      debug:
        msg: "Backup will now archive folders from '{{ backup_root_path }}/opt/'"

    when: (use_snapshot)


  # Start Plexdrive and containers when snapshot is enabled

  - name: Snapshot | Start plexdrive and containers
    block:

    - name: "Snapshot | Start plexdrive service"
      systemd:
        name: plexdrive
        state: started
      when: (plexdrive_service.stat.exists) and (plexdrive_service_running)

    - name: "Snapshot | Wait for 5 seconds before starting containers"
      wait_for:
        timeout: 5

    - name: "Snapshot | Start all previously running Docker containers"
      shell: 'docker start {{ cloudbox_managed_containers.stdout }}'
      ignore_errors: yes
      when: (cloudbox_managed_containers.stdout | trim | length > 0)

    - name: "Snapshot | Pushover Message: Started Docker containers"
      include_role:
        name: pushover
      vars:
        message: "Started Docker containers."
      when: (cloudbox_managed_containers.stdout | trim | length > 0)

    when: (use_snapshot)

  - name: "Get list of all folders in '{{ backup_root_path }}/opt/'"
    find:
      paths: "{{ backup_root_path }}/opt"
      recurse: no
      file_type: directory
    register: opt_folders_temp

  - name: Create 'opt_folders' variable
    set_fact:
      opt_folders: []

  - name: Add folder list to 'opt_folders' variable
    set_fact:
      opt_folders: "{{ opt_folders }} + [ '{{ item.path }}' ]"
    with_items: "{{ opt_folders_temp.files }}"
    loop_control:
      label: "{{ item.path }}"

  - name: "Archiving '{{ backup_root_path }}/opt/' folders into '{{ local.destination }}/'"
    shell: |
      tar \
        --ignore-failed-read \
        --warning=no-file-changed \
        --warning=no-file-removed \
        --exclude-from '{{ (backup_excludes_list is defined and backup_excludes_list.stat.exists) | ternary(playbook_dir + '/backup_excludes_list.txt', playbook_dir + '/roles/backup/files/backup_excludes_list.txt') }}' \
        -cf '{{ local.destination }}/opt/{{ item | basename }}.tar' -C '{{ item | dirname }}' './{{ item | basename }}' \
        2> /dev/null
    args:
      executable: /bin/bash
      warn: no
    with_items: "{{ opt_folders }}"
    loop_control:
      label: "'{{ item }}' --> '{{ local.destination }}/opt/{{ item | basename }}.tar'"

  - name: Snapshot | Delete btrfs snapshot
    shell: btrfs subvolume delete /btrfs/snapshots/root &> /dev/null || true
    when: (use_snapshot) and (snapshot_type == 'btrfs')

  - name: Check if tar files were created
    find:
      paths: "{{ local.destination }}/opt/"
      file_type: file
      patterns: '*.tar'
    register: dir_files2

  - name: Abort backup when tar creation fails
    fail: msg="There must have been an issue during the tar creation tasks as they are missing in '{{ local.destination }}/opt/'"
    when: (dir_files2.matched|int == 0)

  - name: "Remove '{{ local.destination }}.old'"
    file:
      path: "{{ local.destination }}.old"
      state: absent
    become: yes
    become_user: "{{ user }}"
    when: (dir_files2.matched|int != 0)

  - name: "Get size of '{{ local.destination }}'"
    shell: du -s -B1 --apparent-size {{ local.destination }} | awk '{print $1}'
    register: backup_new

  - name: "Set backup_size"
    set_fact:
      backup_size: "{{ (backup_new.stdout|int) | filesizeformat }}"

  - name: "Pushover Message: Backup created. Total size = {{ backup_size }}."
    include_role:
      name: pushover
    vars:
      message: "Backup created. Total size = {{ backup_size }}."
    ignore_errors: yes

  # Start Plexdrive and containers when snapshot is not enabled

  - name: Start plexdrive and containers
    block:

    - name: "Start plexdrive service"
      systemd:
        name: plexdrive
        state: started
      when: (plexdrive_service.stat.exists) and (plexdrive_service_running)

    - name: "Wait for 5 seconds before starting containers"
      wait_for:
        timeout: 5

    - name: "Start all previously running Docker containers"
      shell: 'docker start {{ cloudbox_managed_containers.stdout }}'
      ignore_errors: yes
      when: (cloudbox_managed_containers.stdout | trim | length > 0)

    - name: "Pushover Message: Started Docker containers"
      include_role:
        name: pushover
      vars:
        message: "Started Docker containers."
      when: (cloudbox_managed_containers.stdout | trim | length > 0)

    when: (not use_snapshot)

  - name: "Wait for 10 seconds before uploads"
    wait_for:
      timeout: 10

  - name: "Reset folder ownership"
    shell: "chown -R {{ user }}:{{ user }} {{ local.destination }}/"
    args:
      warn: no

  # Reset mod dates to avoid conflicts during rclone backup. Ansible module doesn't touch folder contents via wildcard.
  - name: "Reset permissions and mod dates to files in '{{ local.destination }}/'"
    shell: find '{{ local.destination }}' -type f  -exec touch {} +
    become: yes
    become_user: "{{ user }}"
    args:
      executable: /bin/bash
      warn: no

  # Due to a touch command in a previous backup, all files on rclone.destination have same mod dates, therefore, only one file's mod date is needed.
  - name: "Get datestamp for previous '{{ rclone.destination }}/settings.yml'"
    shell: |
      /usr/bin/rclone lsl \
        {{ rclone.destination }}/settings.yml \
        --user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36' \
        | sed -e 's/^[ \t]*//' | cut -d ' ' -f 2,3 | cut -d '.' -f 1 | sed s/' '/_/g | sed s/':'/./g
    become: yes
    become_user: "{{ user }}"
    register: rclone_timestamp
    ignore_errors: yes
    when: (rclone.enable)

  # If rclone_timestamp is blank (would happen if settings.yml was not at destination), default the naming of files to '/archived/old/filename.ext', else /archived/date/filename.ext.
  - name: "Archive previous files in '{{ rclone.destination }}'"
    shell: |
      /usr/bin/rclone moveto \
        --user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36' \
        '{{ rclone.destination }}/{{ item }}' '{{ rclone.destination }}/archived/{{ (rclone_timestamp.stdout) if (rclone_timestamp is defined) else 'old' }}/{{ item }}' \
        2>/dev/null
    become: yes
    become_user: "{{ user }}"
    register: rclone_move
    failed_when: rclone_move.rc > 3
    ignore_errors: yes
    when: (rclone.enable)
    with_items:
     - "opt"
     - "ansible.cfg"
     - "accounts.yml"
     - "settings.yml"
     - "adv_settings.yml"
     - "backup_config.yml"
     - "rclone.conf"
     - "backup_excludes.txt"
     - "backup_excludes_list.txt"

  - name: "Wait for 5 seconds before uploading"
    wait_for:
      timeout: 5

  - name: "Use rclone to upload backup to '{{ rclone.destination }}'"
    shell: |
      /usr/bin/rclone copy \
        --user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36' \
        --transfers=4 \
        --drive-chunk-size=128M \
        --stats=30s \
        -v \
        --log-file='/home/{{ user }}/logs/backup/cloudbox_backup_rclone.log' \
        '{{ local.destination }}' '{{ rclone.destination }}'
    become: yes
    become_user: "{{ user }}"
    when: (rclone.enable)

  - name: "Pushover Message: Rclone uploaded backup to '{{ rclone.destination }}'"
    include_role:
      name: pushover
    vars:
      message: "Rclone uploaded backup to '{{ rclone.destination }}'."
    when: (rclone.enable)

  - name: "Use rsync to upload backup to '{{ rsync.destination }}'"
    synchronize:
      src: "{{ local.destination }}/"
      dest: "{{ rsync.destination }}/"
      set_remote_user: yes
      compress: no
    become: yes
    become_user: "{{ user }}"
    when: (rsync.enable)

  - name: "Pushover Message: Rsync uploaded backup to '{{ rsync.destination }}'"
    include_role:
      name: pushover
    vars:
      message: "Rsync uploaded backup to '{{ rsync.destination }}'."
    when: (rsync.enable)

  - name: Get Current Time
    shell: "date \"+%s\""
    register: end_time_lookup

  - name: "Set 'end_time' variable"
    set_fact:
      end_time: "{{ end_time_lookup.stdout }}"

  - name: "Calculate Total Time"
    set_fact:
      total_time: "{{ (((end_time|int) - (start_time|int)) / 60) | int | abs }}"

  - name: "Pushover Message: Finished Cloudbox backup task in {{ total_time }} minutes"
    include_role:
      name: pushover
    vars:
      message: "Finished Cloudbox {{ use_snapshot | ternary('(snapshot-enabled) ','') }}backup task in {{ total_time }} minutes."

  - name: "Start cloudplow service"
    systemd:
      name: cloudplow
      state: started
    when: (cloudplow_service.stat.exists) and (cloudplow_service_running)

  - name: "Remove {{ local.destination }}"
    file:
      path: "{{ local.destination }}"
      state: absent
    when: (dir_files2.matched|int != 0) and (not local.enable)

  - name: Backup Status - Success
    debug:
      msg: "Backup Completed Successfully."

  rescue:
  - name: Snapshot | Delete btrfs snapshot
    shell: btrfs subvolume delete /btrfs/snapshots/root &> /dev/null || true
    when: (use_snapshot) and (snapshot_type == 'btrfs')

  - name: "Reset folder ownership"
    shell: "chown -R {{ user }}:{{ user }} {{ local.destination }}/"
    args:
      warn: no

  - name: Start plexdrive and containers
    block:

    - name: "Start plexdrive service"
      systemd:
        name: plexdrive
        state: started
      when: (plexdrive_service is defined) and (plexdrive_service.stat.exists) and (plexdrive_service_running)

    - name: "Wait for 5 seconds before starting containers"
      wait_for:
        timeout: 5

    - name: "Start all previously running Docker containers"
      shell: 'docker start {{ cloudbox_managed_containers.stdout }}'
      ignore_errors: yes
      when: (cloudbox_managed_containers.stdout | trim | length > 0)

    when: (not use_snapshot)

  - name: "Start cloudplow service"
    systemd:
      name: cloudplow
      state: started
    when: (cloudplow_service is defined) and (cloudplow_service.stat.exists) and (cloudplow_service_running)

  - name: Backup Status - Failure
    debug:
      msg: 'Backup terminated due to an error'

  - name: "Pushover Message: Backup terminated due to an error"
    include_role:
      name: pushover
    vars:
      message: "Backup terminated due to an error."

  always:
  - name: "Remove 'backup.lock'"
    file:
      path: "{{ playbook_dir }}/backup.lock"
      state: absent

  - name: "Reset logs folder ownership."
    shell: "chown -R {{ user }}:{{ user }} '/home/{{ user }}/logs/'"
    args:
      warn: no
